{
  "schema_version": "1.0",
  "created_at": "2025-11-18T15:42:02.792618+00:00",
  "last_modified": "2025-11-27T21:54:01.252686+00:00",
  "enable_mcp_classification": false,
  "default_consumption_profile": "Unlimited",
  "consumption_profiles": [
    {
      "name": "Free",
      "description": "Free tier with basic limits",
      "prompts_per_hour": 50,
      "prompts_per_day": 500,
      "config_changes_per_hour": 5,
      "input_tokens_per_month": 100000,
      "output_tokens_per_month": 50000,
      "is_active": true
    },
    {
      "name": "Pro",
      "description": "Professional tier with higher limits",
      "prompts_per_hour": 200,
      "prompts_per_day": 2000,
      "config_changes_per_hour": 20,
      "input_tokens_per_month": 500000,
      "output_tokens_per_month": 250000,
      "is_active": true
    },
    {
      "name": "Enterprise",
      "description": "Enterprise tier with high limits",
      "prompts_per_hour": 500,
      "prompts_per_day": 5000,
      "config_changes_per_hour": 50,
      "input_tokens_per_month": 2000000,
      "output_tokens_per_month": 1000000,
      "is_active": true
    },
    {
      "name": "Unlimited",
      "description": "Unlimited tier with no token limits",
      "prompts_per_hour": 1000,
      "prompts_per_day": 10000,
      "config_changes_per_hour": 100,
      "input_tokens_per_month": null,
      "output_tokens_per_month": null,
      "is_active": true
    }
  ],
  "rag_collections": [],
  "mcp_servers": [
    {
      "name": "Teradata MCP",
      "host": "uderia.com",
      "port": "8888",
      "path": "/mcp",
      "id": "1763483266562-a6kulj4xc",
      "all_tools": [],
      "all_prompts": []
    }
  ],
  "active_mcp_server_id": null,
  "llm_configurations": [
    {
      "name": "Google Flash",
      "provider": "Google",
      "model": "gemini-2.0-flash",
      "credentials": {},
      "id": "1763819257473-ivpnukbbe"
    },
    {
      "name": "Friendli - Gemma",
      "provider": "Friendli",
      "model": "google/gemma-3-27b-it",
      "credentials": {},
      "id": "1763819257483-fluhef2vk"
    },
    {
      "name": "OpenAI - 4omini",
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "credentials": {},
      "id": "1763832180990-t4s6q1lhy"
    },
    {
      "name": "Anthropic -Haiku",
      "provider": "Anthropic",
      "model": "claude-3-5-haiku-20241022",
      "credentials": {},
      "id": "1763891767248-f1b77hlqi"
    },
    {
      "name": "Azure - 4omini",
      "provider": "Azure",
      "model": "tda-gpt-4o-mini",
      "credentials": {},
      "id": "1763892145444-ix871l09b"
    },
    {
      "name": "Amazon - NovaLite",
      "provider": "Amazon",
      "model": "amazon.nova-lite-v1:0",
      "credentials": {},
      "id": "1763892251792-fvxyy5msd"
    }
  ],
  "active_llm_configuration_id": null,
  "profiles": [
    {
      "id": "profile-default-chat",
      "name": "Conversation Focused",
      "tag": "CHAT",
      "description": "Direct conversation with LLM (no tools)",
      "profile_type": "llm_only",
      "llmConfigurationId": null,
      "mcpServerId": null,
      "classification_mode": null,
      "tools": ["*"],
      "prompts": ["*"],
      "ragCollections": [],
      "autocompleteCollections": [],
      "useMcpTools": false,
      "useKnowledgeCollections": false,
      "classification_results": {
        "tools": {},
        "prompts": {},
        "resources": {},
        "classified_with_mode": null,
        "last_classified": null
      },
      "isDefault": false
    },
    {
      "id": "profile-1763993711628-vvbh23q09",
      "name": "Efficiency Focused - Google Flash",
      "tag": "GOGET",
      "description": "Optimized execution via Planner/Executor",
      "profile_type": "tool_enabled",
      "llmConfigurationId": "1763819257473-ivpnukbbe",
      "mcpServerId": "1763483266562-a6kulj4xc",
      "classification_mode": "full",
      "tools": ["*"],
      "prompts": ["*"],
      "ragCollections": [],
      "autocompleteCollections": [],
      "classification_results": {
        "tools": {},
        "prompts": {},
        "resources": {},
        "classified_with_mode": null,
        "last_classified": null
      },
      "isDefault": false
    },
    {
      "id": "profile-1764006444002-z0hdduce9",
      "name": "Friendly AI - Reduced Stack",
      "tag": "FRGOT",
      "description": "Friendly",
      "profile_type": "tool_enabled",
      "llmConfigurationId": "1763819257483-fluhef2vk",
      "mcpServerId": "1763483266562-a6kulj4xc",
      "classification_mode": "light",
      "tools": ["*"],
      "prompts": ["*"],
      "ragCollections": [],
      "autocompleteCollections": [],
      "classification_results": {
        "tools": {},
        "prompts": {},
        "resources": {},
        "classified_with_mode": null,
        "last_classified": null
      },
      "inherit_classification": true,
      "isDefault": false
    },
    {
      "id": "profile-default-rag",
      "name": "Knowledge Focused",
      "tag": "RAG",
      "description": "Search knowledge base with LLM synthesis (requires knowledge collections)",
      "profile_type": "rag_focused",
      "llmConfigurationId": null,
      "mcpServerId": null,
      "knowledgeConfig": {
        "enabled": true,
        "collections": [],
        "maxDocs": 10,
        "minRelevanceScore": 0.7,
        "maxTokens": 2000
      },
      "isDefault": false
    },
    {
      "id": "profile-default-genie",
      "name": "Multi-Expert Coordinator",
      "tag": "GENIE",
      "description": "Coordinates multiple profiles to answer complex questions",
      "profile_type": "genie",
      "llmConfigurationId": null,
      "mcpServerId": null,
      "genieConfig": {
        "slaveProfiles": [],
        "maxConcurrentSlaves": 3
      },
      "isDefault": false
    }
  ],
  "active_profile_id": null,
  "default_profile_id": null,
  "master_classification_profile_id": null,
  "active_for_consumption_profile_ids": [],
  "rate_limit_enabled": "on",
  "rate_limit_global_override": "off",
  "window_defaults": {
    "session_history_expanded": false,
    "resources_expanded": false,
    "status_expanded": false,
    "allow_user_override": true,
    "always_show_welcome_screen": true,
    "default_theme": "modern"
  },
  "default_model_costs": [
    {
      "provider": "Friendli",
      "model": "google/gemma-3-27b-it",
      "input_cost_per_million": 0.03,
      "output_cost_per_million": 0.03,
      "notes": "Friendli serverless @ $0.002/sec, ~70 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "meta-llama/Llama-3.3-70B-Instruct",
      "input_cost_per_million": 0.6,
      "output_cost_per_million": 0.6,
      "notes": "Friendli serverless @ $0.6/1M tokens"
    },
    {
      "provider": "Friendli",
      "model": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_million": 0.2,
      "output_cost_per_million": 0.8,
      "notes": "Friendli serverless @ $0.2 input, $0.8 output per 1M tokens"
    },
    {
      "provider": "Friendli",
      "model": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_million": 0.004,
      "output_cost_per_million": 0.004,
      "notes": "Friendli serverless @ $0.004/sec, ~50 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "mistralai/Magistral-Small-2506",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "mistralai/Devstral-Small-2505",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "Qwen/Qwen3-32B",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "skt/A.X-31",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "zal-org/GLM-4-6",
      "input_cost_per_million": 0.004,
      "output_cost_per_million": 0.004,
      "notes": "Friendli serverless @ $0.004/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "Qwen/Qwen3-30B-A3B",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "input_cost_per_million": 0.004,
      "output_cost_per_million": 0.004,
      "notes": "Friendli serverless @ $0.004/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "deepseek-ai/DeepSeek-V3.1",
      "input_cost_per_million": 0.004,
      "output_cost_per_million": 0.004,
      "notes": "Friendli serverless @ $0.004/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "skt/A.X-4.0",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "naver-hyperclovax/HyperCLOVAX-SEED-Think-14B",
      "input_cost_per_million": 0.002,
      "output_cost_per_million": 0.002,
      "notes": "Friendli serverless @ $0.002/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Friendli",
      "model": "LGAI-EXAONE/EXAONE-4.0.1-32B",
      "input_cost_per_million": 0.6,
      "output_cost_per_million": 1.0,
      "notes": "Friendli serverless @ $0.6 input, $1 output per 1M tokens"
    },
    {
      "provider": "Friendli",
      "model": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_million": 0.004,
      "output_cost_per_million": 0.004,
      "notes": "Friendli serverless @ $0.004/sec, ~100 tokens/sec avg"
    },
    {
      "provider": "Fallback",
      "model": "Unknown Models",
      "input_cost_per_million": 0.10,
      "output_cost_per_million": 0.40,
      "is_fallback": true,
      "notes": "Default fallback cost for models not found in pricing table (based on Gemini Flash pricing)"
    }
  ],
  "global_parameters": {
    "mcp_system_name": "Teradata MCP"
  },
  "default_prompt_mappings": {
    "master_system_prompts": {
      "Google": "GOOGLE_MASTER_SYSTEM_PROMPT",
      "Anthropic": "MASTER_SYSTEM_PROMPT",
      "Amazon": "MASTER_SYSTEM_PROMPT",
      "OpenAI": "MASTER_SYSTEM_PROMPT",
      "Azure": "MASTER_SYSTEM_PROMPT",
      "Friendli": "MASTER_SYSTEM_PROMPT",
      "Ollama": "OLLAMA_MASTER_SYSTEM_PROMPT"
    },
    "workflow_classification": {
      "task_classification": "TASK_CLASSIFICATION_PROMPT",
      "workflow_meta_planning": "WORKFLOW_META_PLANNING_PROMPT",
      "workflow_tactical": "WORKFLOW_TACTICAL_PROMPT"
    },
    "error_recovery": {
      "error_recovery": "ERROR_RECOVERY_PROMPT",
      "tactical_self_correction": "TACTICAL_SELF_CORRECTION_PROMPT",
      "self_correction_column_error": "TACTICAL_SELF_CORRECTION_PROMPT_COLUMN_ERROR",
      "self_correction_table_error": "TACTICAL_SELF_CORRECTION_PROMPT_TABLE_ERROR"
    },
    "data_operations": {
      "sql_consolidation": "SQL_CONSOLIDATION_PROMPT"
    },
    "visualization": {
      "charting_instructions": "CHARTING_INSTRUCTIONS",
      "g2plot_guidelines": "G2PLOT_GUIDELINES"
    },
    "conversation_execution": {
      "conversation": "CONVERSATION_EXECUTION",
      "conversation_with_tools": "CONVERSATION_WITH_TOOLS_EXECUTION"
    },
    "rag_focused_execution": {
      "rag_focused_execution": "RAG_FOCUSED_EXECUTION"
    },
    "genie_coordination": {
      "coordinator_prompt": "GENIE_COORDINATOR_PROMPT"
    }
  }
}
